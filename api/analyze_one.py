import json
import os
import traceback
import time
from concurrent.futures import ThreadPoolExecutor, as_completed
from flask import Flask, request, jsonify

try:
    # Reuse logic from cron_analyze
    from cron_analyze import _load_sb, _analyze_video
except Exception:
    _load_sb = None
    _analyze_video = None

# --- Fallback implementations if import fails ---
if _load_sb is None or _analyze_video is None:
    try:
        from supabase import create_client
    except Exception:
        create_client = None

    import requests

    def _load_sb():  # type: ignore
        if create_client is None:
            raise RuntimeError('supabase client not available')
        url = os.getenv('SUPABASE_URL')
        key = os.getenv('SUPABASE_SERVICE_ROLE_KEY') or os.getenv('SUPABASE_ANON_KEY')
        if not url or not key:
            raise RuntimeError('Missing SUPABASE_URL or SUPABASE_*_KEY env')
        return create_client(url, key)

    def _call_gemini(system_prompt: str, user_content: str) -> str:
        api_key = os.getenv('GEMINI_API_KEY')
        if not api_key:
            raise RuntimeError('GEMINI_API_KEY not set')
        prefer = os.getenv('GEMINI_MODEL')
        candidates = [
            *( [prefer] if prefer else [] ),
            'models/gemini-2.5-flash',
            'models/gemini-2.0-flash-exp',
            'models/gemini-1.5-flash-latest',
            'models/gemini-1.5-pro-latest',
        ]
        payload = {
            'contents': [
                { 'role': 'user', 'parts': [{ 'text': f"{system_prompt}\n\n{user_content}" }] }
            ],
            'generationConfig': { 'temperature': 0.3 }
        }
        base = 'https://generativelanguage.googleapis.com'
        errors = []
        for api_ver in ('v1', 'v1beta'):
            for model in candidates:
                if not model:
                    continue
                url = f"{base}/{api_ver}/{model}:generateContent?key={api_key}"
                try:
                    res = requests.post(url, json=payload, timeout=90)
                    if res.status_code == 404:
                        errors.append(f"{api_ver}/{model}:404")
                        continue
                    res.raise_for_status()
                    data = res.json()
                    text = data.get('candidates', [{}])[0].get('content', {}).get('parts', [{}])[0].get('text', '')
                    if text:
                        return text
                except Exception as e:
                    errors.append(f"{api_ver}/{model}:{str(e)[:80]}")
                    continue
        raise RuntimeError('Gemini request failed: ' + '; '.join(errors))

    def _persona() -> str:
        return (
            "ë„ˆëŠ” ì´ì œ ë‚´ ìœ íŠœë¸Œ ì±„ë„ì˜ ì„œë¸Œì‘ê°€ì•¼. ë‚´ê°€ ë§Œë“  ìœ íŠœë¸Œ ì‡¼ì¸  ì˜ìƒ ì¤‘ 100ë§Œ ì¡°íšŒìˆ˜ ì´ìƒ ì˜ìƒë§Œ ì¶”ë ¤ë‚´ì„œ "
            "ë¶„ì„í•˜ë ¤ê³  í•´. ë‚´ ê³ ì¡°íšŒìˆ˜ ì˜ìƒ ëŒ€ë³¸ì„ ê¼¼ê¼¼í•˜ê²Œ ë¶„ì„í•´ì„œ ë‚´ ì±„ë„ì˜ ì •ì²´ì„±ì„ íŒŒì•…í•˜ê³  ê²°ì„ ì¡ì•„ê°ˆ ê±°ì•¼. "
            "í•­ìƒ 'ê³ ì¡°íšŒìˆ˜ ì„±ê³µ íŒ¨í„´'ì˜ ê´€ì ì—ì„œ ìš”ì•½ê³¼ ë¶„ë¥˜ë¥¼ í•´ì¤˜."
        )

    def _build_material_prompt() -> str:
        return (
            _persona() + '\n\n'
            'ì•„ë˜ ëŒ€ë³¸ì„ ì½ê³  ë‹¤ìŒ í˜•ì‹ìœ¼ë¡œë§Œ ì¶œë ¥í•˜ì„¸ìš”. ë‹¤ë¥¸ í…ìŠ¤íŠ¸ ê¸ˆì§€.\n'
            'ë©”ì¸ ì•„ì´ë””ì–´ (Main Idea): (ì˜ìƒì´ ì „ë‹¬í•˜ë ¤ëŠ” í•µì‹¬ ë©”ì‹œì§€ë¥¼ 1ë¬¸ì¥ìœ¼ë¡œ)\n\n'
            'í•µì‹¬ ì†Œì¬ (Core Materials):\n- í•­ëª©ì€ 3~7ê°œ, ê°„ê²°í•œ ëª…ì‚¬êµ¬ë¡œ ë¶ˆë¦¿ ë¦¬ìŠ¤íŠ¸ ì‘ì„±\n- ë¶ˆí•„ìš”í•œ ìˆ˜ì‹/ì´ëª¨ì§€/ì½”ë“œë¸”ë¡ ê¸ˆì§€\n\n'
            '3-1 ë°˜ë³µë˜ëŠ” ì–¸ì–´ íŒ¨í„´: (ë¶ˆë¦¿ìœ¼ë¡œ 3~6ê°œ, í‘œí˜„ ìŠµê´€/êµ¬ì ˆ/ì ‘ì†ì–´ ë“±)\n'
            '3-2 ê°ì • ëª°ì… í¬ì¸íŠ¸: (ë¶ˆë¦¿ìœ¼ë¡œ 3~6ê°œ, í˜¸ê¸°ì‹¬/ê¸´ì¥/ì¹´íƒ€ë¥´ì‹œìŠ¤ ìœ ë°œ ì¥ì¹˜)\n'
            '3-3 ì •ë³´ ì „ë‹¬ ë°©ì‹ íŠ¹ì§•: (ë¶ˆë¦¿ìœ¼ë¡œ 3~6ê°œ, ì „ê°œ ì†ë„/í¸ì§‘/ë‚˜ë ˆì´ì…˜/ì¹´í”¼í†¤ ë“±)'
        )

    def _build_hooking_prompt() -> str:
        return (
            _persona() + '\n\n'
            '2. í›„í‚¹ í”„ë¡¬í”„íŠ¸ â€” "ì˜ìƒì— ì“°ì¸ í›„í‚¹ íŒ¨í„´ì€?"\n'
            'ëŒ€ë³¸ì˜ ì‹œì‘ë¶€(ê°€ëŠ¥í•˜ë©´ ì²« ë¬¸ì¥ ê¸°ì¤€)ì—ì„œ ì‹œì²­ìì˜ ê¶ê¸ˆì¦ì„ ìœ ë°œí•œ í•µì‹¬ì„ 1ì¤„ë¡œ "ìš”ì•½"í•˜ê³ , ì‚¬ìš©ëœ í›„í‚¹ íŒ¨í„´ì„ ë¶„ë¥˜í•´ í‘œë¡œ ì‘ì„±í•˜ì„¸ìš”.\n'
            'ì¶œë ¥ì€ ë§ˆí¬ë‹¤ìš´ í‘œ í•œ ê°œë§Œ(ì—´ ë¨¸ë¦¬ í¬í•¨), ë‹¤ë¥¸ í…ìŠ¤íŠ¸ ê¸ˆì§€.\n'
            '| ğŸ¤” í›„í‚¹ ìš”ì•½ | íŒ¨í„´(ë¶„ë¥˜) |\n| :--- | :--- |\n| (ì‹œì‘ë¶€ ìš”ì•½ 1ì¤„) | (ì˜ˆ: ì˜ë¬¸ì œì‹œ/ê³¼ì¥/ë°˜ì „/ìœ„ê¸°ì œì‹œ/ê¸ˆê¸°ë°œí™”/ê°•í•œëª…ë ¹/ëª¨ìˆœ ì œì‹œ ë“±) |'
        )

    def _build_structure_prompt() -> str:
        return (
            _persona() + '\n\n'
            '1. ê¸°ìŠ¹ì „ê²° í”„ë¡¬í”„íŠ¸ â€” "ì˜ìƒì— ë‚˜íƒ€ë‚˜ëŠ” ê¸°ìŠ¹ì „ê²° êµ¬ì¡°ëŠ”?"\n'
            'ëŒ€ë³¸ì—ì„œ ê¸°Â·ìŠ¹Â·ì „Â·ê²°ì˜ í•µì‹¬ì„ ê° 1ë¬¸ì¥ìœ¼ë¡œ "ìš”ì•½"í•´ í‘œë¡œ ì‘ì„±í•˜ì„¸ìš”(ì›ë¬¸ ë³µì‚¬ ê¸ˆì§€).\n'
            'ì¶œë ¥ì€ ë§ˆí¬ë‹¤ìš´ í‘œ í•œ ê°œë§Œ, ë‹¤ë¥¸ í…ìŠ¤íŠ¸ ê¸ˆì§€.\n'
            '| êµ¬ë¶„ | ìš”ì•½ |\n| :--- | :--- |\n| ê¸° (ìƒí™© ë„ì…) | ... |\n| ìŠ¹ (ì‚¬ê±´ ì „ê°œ) | ... |\n| ì „ (ìœ„ê¸°/ì „í™˜) | ... |\n| ê²° (ê²°ë§) | ... |'
        )

    def _clean_sentences_ko(text: str):
        t = (text or '')
        # remove brackets and markers
        import re
        t = re.sub(r"\[[^\]]*\]", " ", t)
        t = re.sub(r"^\s*>>.*", " ", t, flags=re.MULTILINE)
        t = re.sub(r"\b(ìŒì•…|ë°•ìˆ˜|ì›ƒìŒ|ì¹¨ë¬µ|ë°°ê²½ìŒ|ê¸°ì¹¨)\b", " ", t, flags=re.IGNORECASE)
        t = t.replace('\r', '\n')
        t = re.sub(r"\n{2,}", "\n", t)
        t = re.sub(r"[\t ]{2,}", " ", t)
        # Korean sentence ending hints
        t = re.sub(r"(ìš”|ë‹¤|ì£ |ë„¤|ìŠµë‹ˆë‹¤|ìŠµë‹ˆê¹Œ|ë„¤ìš”|êµ°ìš”)([.!?])", r"\1\2\n", t)
        # split
        parts = re.split(r"(?<=[.!?â€¦]|\n)\s+", t)
        parts = [p.strip() for p in parts if p and p.strip()]
        # merge short
        out = []
        buf = ''
        MIN = 10
        for p in parts:
            cur = (buf + ' ' + p).strip() if buf else p
            if len(cur) < MIN:
                buf = cur
                continue
            out.append(cur)
            buf = ''
        if buf:
            out.append(buf)
        # remove noise
        out = [s for s in out if len(re.sub(r"[^\w\dê°€-í£]", "", s)) >= 3]
        return out[:300]

    def _estimate_dopamine(sentence: str) -> int:
        s = (sentence or '').lower()
        score = 3
        if any(k in s for k in ['ì¶©ê²©', 'ë°˜ì „', 'ê²½ì•…', 'ë¯¸ì¹œ', 'ëŒ€í­', 'í­ë¡œ', 'ì†Œë¦„', '!', '?']):
            score += 5
        return max(1, min(10, score))

    def _safe_json_arr(text: str):
        try:
            obj = json.loads(text)
            return obj if isinstance(obj, list) else []
        except Exception:
            return []

    def _build_dopamine_prompt(sentences):
        header = 'ë‹¤ìŒ "ë¬¸ì¥ ë°°ì—´"ì— ëŒ€í•´, ê° ë¬¸ì¥ë³„ë¡œ ê¶ê¸ˆì¦/ë„íŒŒë¯¼ ìœ ë°œ ì •ë„ë¥¼ 1~10 ì •ìˆ˜ë¡œ í‰ê°€í•˜ê³ , ê·¸ ì´ìœ ë¥¼ ê°„ë‹¨íˆ ì„¤ëª…í•˜ì„¸ìš”. ë°˜ë“œì‹œ JSON ë°°ì—´ë¡œë§Œ, ìš”ì†ŒëŠ” {"sentence":"ë¬¸ì¥","level":ì •ìˆ˜,"reason":"ì´ìœ "} í˜•íƒœë¡œ ì¶œë ¥í•˜ì„¸ìš”. ì—¬ëŠ” ëŒ€ê´„í˜¸ë¶€í„° ë‹«ëŠ” ëŒ€ê´„í˜¸ê¹Œì§€ ì™¸ í…ìŠ¤íŠ¸ëŠ” ì¶œë ¥í•˜ì§€ ë§ˆì„¸ìš”.'
        return header + '\n\në¬¸ì¥ ë°°ì—´:\n' + json.dumps(sentences, ensure_ascii=False)

    def _analyze_video_fast(doc):  # type: ignore
        transcript = (doc or {}).get('transcript_text') or ''
        if not transcript:
            raise RuntimeError('no transcript_text in DB')
        # Trim overly long transcripts to improve latency
        max_chars = int(os.getenv('GEMINI_MAX_CHARS') or '12000')
        tshort = transcript if len(transcript) <= max_chars else transcript[:max_chars]
        jobs = {
            'material': (_build_material_prompt(), tshort),
            'hooking': (_build_hooking_prompt(), tshort),
            'structure': (_build_structure_prompt(), tshort)
        }
        results = { 'material': '', 'hooking': '', 'structure': '' }
        with ThreadPoolExecutor(max_workers=3) as ex:
            fut_map = { ex.submit(_call_gemini, p, txt): name for name, (p, txt) in jobs.items() }
            for fut in as_completed(fut_map):
                name = fut_map[fut]
                try:
                    results[name] = (fut.result() or '').strip()
                except Exception as e:
                    results[name] = ''
        # dopamine graph (LLM, chunked)
        sentences = _clean_sentences_ko(tshort)
        dopamine_graph = []
        batch_size = 50
        for i in range(0, len(sentences), batch_size):
            sub = sentences[i:i+batch_size]
            try:
                resp = _call_gemini(_build_dopamine_prompt(sub), '')
                arr = _safe_json_arr(resp)
                for item in arr:
                    s = str(item.get('sentence') or item.get('text') or '')
                    try:
                        level = int(round(float(item.get('level') or item.get('score') or 0)))
                    except Exception:
                        level = 1
                    level = max(1, min(10, level))
                    dopamine_graph.append({ 'sentence': s, 'level': level, 'reason': str(item.get('reason') or '') })
            except Exception:
                # fallback to simple heuristic for this chunk
                for s in sub:
                    dopamine_graph.append({ 'sentence': s, 'level': _estimate_dopamine(s), 'reason': 'heuristic' })
        # Fallbacks to reduce partial-missing fields
        if not results['material']:
            # simple one-line gist using start/mid/end stitching to avoid identical hook
            if sentences:
                first = sentences[0]
                mid = sentences[min(len(sentences)//2, len(sentences)-1)]
                last = sentences[-1]
                gist = ' / '.join([s for s in [first, mid, last] if s])
                results['material'] = gist[:200]
            else:
                top = sorted(dopamine_graph, key=lambda x: x['level'], reverse=True)
                cand = (top[0]['sentence'] if top else (tshort.split('\n')[0] if tshort else ''))
                results['material'] = (cand or '')[:200]
        if not results['hooking']:
            # user preference: first sentence is the hook
            first = sentences[0] if sentences else tshort.split('\n')[0]
            results['hooking'] = (first or '')[:200]
        if not results['structure']:
            if sentences:
                n = len(sentences)
                q1 = sentences[0]
                q2 = sentences[min(n//3, n-1)]
                q3 = sentences[min(2*n//3, n-1)]
                q4 = sentences[-1]
                results['structure'] = f"ê¸°: {q1}\nìŠ¹: {q2}\nì „: {q3}\nê²°: {q4}"
        return {
            'material': results['material'][:2000],
            'hooking': results['hooking'][:2000],
            'narrative_structure': results['structure'][:4000],
            'dopamine_graph': dopamine_graph,
            'analysis_transcript_len': len(transcript),
            'last_modified': int(time.time()*1000)
        }

app = Flask(__name__)

@app.after_request
def add_cors_headers(resp):
    try:
        resp.headers['Access-Control-Allow-Origin'] = '*'
        resp.headers['Access-Control-Allow-Headers'] = 'Content-Type, Authorization'
        resp.headers['Access-Control-Allow-Methods'] = 'GET, POST, OPTIONS'
    except Exception:
        pass
    return resp


@app.route('/', methods=['POST', 'OPTIONS'])
@app.route('/analyze_one', methods=['POST', 'OPTIONS'])
@app.route('/api/analyze_one', methods=['POST', 'OPTIONS'])
def analyze_one():
    if request.method == 'OPTIONS':
        return ('', 204)
    # Readiness: _analyze_videoëŠ” ì‚¬ìš©í•˜ì§€ ì•Šìœ¼ë¯€ë¡œ _load_sbë§Œ í™•ì¸
    if _load_sb is None:
        return jsonify({ 'ok': False, 'error': 'server_not_ready' }), 500
    try:
        stage = 'load_sb'
        sb = _load_sb()
        body = {}
        try:
            body = request.get_json(force=True) or {}
        except Exception:
            body = {}
        vid = str(body.get('id') or '').strip()
        if not vid:
            return jsonify({ 'ok': False, 'error': 'missing id' }), 400
        stage = 'fetch_video'
        row = sb.table('videos').select('*').eq('id', vid).limit(1).execute()
        rows = getattr(row, 'data', []) or []
        if not rows:
            return jsonify({ 'ok': False, 'error': 'not_found' }), 404
        video = rows[0]
        stage = 'analyze'
        # use faster analyzer
        updated = _analyze_video_fast(video) or {}
        if updated:
            # ìŠ¤í‚¤ë§ˆì— ì—†ëŠ” ì»¬ëŸ¼ì€ ì œê±°
            allowed = set(video.keys())
            payload = { k: v for k, v in updated.items() if k in allowed }
            if payload:
                stage = 'update'
                sb.table('videos').update(payload).eq('id', vid).execute()
        wanted = list(updated.keys()) if updated else []
        saved = list(payload.keys()) if updated else []
        skipped = [k for k in wanted if k not in (saved or [])]
        return jsonify({ 'ok': True, 'updated': bool(updated), 'saved_keys': saved, 'skipped_keys': skipped })
    except Exception as e:
        app.logger.exception('analyze_one failed')
        return jsonify({ 'ok': False, 'error': str(e), 'stage': locals().get('stage', 'unknown'), 'trace': traceback.format_exc()[:2000] }), 500


@app.route('/health', methods=['GET'])
def health():
    return ('ok', 200)

@app.route('/debug', methods=['GET'])
@app.route('/api/analyze_one/debug', methods=['GET'])
def debug():
    try:
        info = {
            'has_SUPABASE_URL': bool(os.getenv('SUPABASE_URL')),
            'has_SUPABASE_SERVICE_ROLE_KEY': bool(os.getenv('SUPABASE_SERVICE_ROLE_KEY')),
            'has_SUPABASE_ANON_KEY': bool(os.getenv('SUPABASE_ANON_KEY')),
            'has_GEMINI_API_KEY': bool(os.getenv('GEMINI_API_KEY')),
            'routes': ['/api/analyze_one', '/api/analyze_one/debug', '/api/health']
        }
        return jsonify({ 'ok': True, 'env': info })
    except Exception as e:
        return jsonify({ 'ok': False, 'error': str(e) }), 500


