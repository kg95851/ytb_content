import json
import os
import traceback
import time
from concurrent.futures import ThreadPoolExecutor, as_completed
from flask import Flask, request, jsonify

try:
    # Reuse logic from cron_analyze
    from cron_analyze import _load_sb, _analyze_video
except Exception:
    _load_sb = None
    _analyze_video = None

# --- Fallback implementations if import fails ---
if _load_sb is None or _analyze_video is None:
    try:
        from supabase import create_client
    except Exception:
        create_client = None

    import requests
    
    # Global key rotation state
    _gemini_key_index = 0

    def _load_sb():  # type: ignore
        if create_client is None:
            raise RuntimeError('supabase client not available')
        url = os.getenv('SUPABASE_URL')
        key = os.getenv('SUPABASE_SERVICE_ROLE_KEY') or os.getenv('SUPABASE_ANON_KEY')
        if not url or not key:
            raise RuntimeError('Missing SUPABASE_URL or SUPABASE_*_KEY env')
        return create_client(url, key)
    
    def _get_next_gemini_key():
        global _gemini_key_index
        # Get multiple keys from environment
        keys = []
        
        # Try comma-separated first (GEMINI_API_KEYS="key1,key2,key3")
        multi_keys = os.getenv('GEMINI_API_KEYS')
        if multi_keys:
            keys = [k.strip() for k in multi_keys.split(',') if k.strip()]
            print(f"Found {len(keys)} keys from GEMINI_API_KEYS")
        
        # Also try numbered keys (GEMINI_API_KEY1, GEMINI_API_KEY2, etc.)
        if not keys:
            for i in range(1, 101):
                key = os.getenv(f'GEMINI_API_KEY{i}')
                if key:
                    # Remove quotes if present (common mistake)
                    key = key.strip().strip('"').strip("'")
                    if key and key.startswith('AIza'):  # Valid Gemini key format
                        keys.append(key)
                        print(f"Found GEMINI_API_KEY{i}")
            if keys:
                print(f"Total {len(keys)} numbered keys found")
        
        # Fall back to single key
        if not keys:
            single_key = os.getenv('GEMINI_API_KEY')
            if single_key:
                single_key = single_key.strip().strip('"').strip("'")
                keys = [single_key]
                print("Using single GEMINI_API_KEY")
        
        if not keys:
            # Debug: show what environment variables exist
            env_vars = [k for k in os.environ.keys() if 'GEMINI' in k]
            print(f"Available GEMINI env vars: {env_vars}")
            raise RuntimeError('No valid GEMINI_API_KEY found')
        
        # Rotate through keys
        key = keys[_gemini_key_index % len(keys)]
        _gemini_key_index += 1
        print(f"Using Gemini key #{(_gemini_key_index % len(keys)) + 1} of {len(keys)}")
        return key, len(keys)

    def _call_gemini(system_prompt: str, user_content: str) -> str:
        import time
        prefer = os.getenv('GEMINI_MODEL')
        candidates = [
            *( [prefer] if prefer else [] ),
            'models/gemini-2.5-flash',
            'models/gemini-2.0-flash-exp',
            'models/gemini-1.5-flash-latest',
            'models/gemini-1.5-pro-latest',
        ]
        payload = {
            'contents': [
                { 'role': 'user', 'parts': [{ 'text': f"{system_prompt}\n\n{user_content}" }] }
            ],
            'generationConfig': { 'temperature': 0.3 }
        }
        base = 'https://generativelanguage.googleapis.com'
        all_errors = []
        
        # Try with multiple keys (up to 3 attempts with different keys)
        max_key_attempts = 3
        for key_attempt in range(max_key_attempts):
            try:
                api_key, total_keys = _get_next_gemini_key()
            except Exception as e:
                # If no keys available, use the error from key getter
                raise RuntimeError(str(e))
            
            errors = []
            
            # Adaptive delay based on key rotation (balanced for stability)
            if key_attempt > 0:
                # Exponential backoff for retries
                delay = min(10, 3 * (key_attempt ** 1.5))
                time.sleep(delay)  # Progressive delay: 3s, 4.2s, 5.2s...
                print(f"Retrying with key {key_attempt+1}/{total_keys} after {delay:.1f}s delay")
            else:
                time.sleep(0.5)  # Initial delay for stability
            
            for api_ver in ('v1', 'v1beta'):
                for model in candidates:
                    if not model:
                        continue
                    url = f"{base}/{api_ver}/{model}:generateContent?key={api_key}"
                    try:
                        res = requests.post(url, json=payload, timeout=120)  # Increased timeout for complete responses
                        if res.status_code == 429:
                            # Rate limited - try next key
                            errors.append(f"{api_ver}/{model}:429-key{key_attempt+1}/{total_keys}")
                            break  # Break inner loop to try next key
                        if res.status_code == 404:
                            errors.append(f"{api_ver}/{model}:404")
                            continue
                        res.raise_for_status()
                        data = res.json()
                        text = data.get('candidates', [{}])[0].get('content', {}).get('parts', [{}])[0].get('text', '')
                        if text:
                            return text
                    except Exception as e:
                        error_str = str(e)[:80]
                        errors.append(f"{api_ver}/{model}:{error_str}")
                        if '429' in error_str or 'Too Many Requests' in error_str:
                            # Rate limited - try next key
                            break
                        continue
                
                # If we got rate limited with this key, break to try next key
                if any('429' in e for e in errors):
                    break
            
            all_errors.extend(errors)
            
            # If we didn't get rate limited, no point trying more keys
            if not any('429' in e for e in errors):
                break
        
        raise RuntimeError('Gemini request failed: ' + '; '.join(all_errors))

    def _persona() -> str:
        return (
            "ë„ˆëŠ” ì´ì œ ë‚´ ìœ íŠœë¸Œ ì±„ë„ì˜ ì„œë¸Œì‘ê°€ì•¼. ë‚´ê°€ ë§Œë“  ìœ íŠœë¸Œ ì‡¼ì¸  ì˜ìƒ ì¤‘ 100ë§Œ ì¡°íšŒìˆ˜ ì´ìƒ ì˜ìƒë§Œ ì¶”ë ¤ë‚´ì„œ "
            "ë¶„ì„í•˜ë ¤ê³  í•´. ë‚´ ê³ ì¡°íšŒìˆ˜ ì˜ìƒ ëŒ€ë³¸ì„ ê¼¼ê¼¼í•˜ê²Œ ë¶„ì„í•´ì„œ ë‚´ ì±„ë„ì˜ ì •ì²´ì„±ì„ íŒŒì•…í•˜ê³  ê²°ì„ ì¡ì•„ê°ˆ ê±°ì•¼. "
            "í•­ìƒ 'ê³ ì¡°íšŒìˆ˜ ì„±ê³µ íŒ¨í„´'ì˜ ê´€ì ì—ì„œ ìš”ì•½ê³¼ ë¶„ë¥˜ë¥¼ í•´ì¤˜."
        )

    def _build_material_prompt() -> str:
        return (
            _persona() + '\n\n'
            'ì•„ë˜ ëŒ€ë³¸ì„ ì½ê³  ë°˜ë“œì‹œ JSONë§Œ ì¶œë ¥í•˜ì„¸ìš”. ë‹¤ë¥¸ í…ìŠ¤íŠ¸/ë¨¸ë¦¬ë§/ì½”ë“œíœìŠ¤ ê¸ˆì§€.\n'
            '{\n'
            '  "main_idea": "ì˜ìƒì´ ì „ë‹¬í•˜ë ¤ëŠ” í•µì‹¬ ë©”ì‹œì§€ë¥¼ 1ë¬¸ì¥",\n'
            '  "core_materials": ["í•µì‹¬ ì†Œì¬ë¥¼ 3~7ê°œ, ê°„ê²°í•œ ëª…ì‚¬êµ¬"],\n'
            '  "lang_patterns": ["ë°˜ë³µë˜ëŠ” ì–¸ì–´/í‘œí˜„ 3~6ê°œ"],\n'
            '  "emotion_points": ["ê°ì • ëª°ì… í¬ì¸íŠ¸ 3~6ê°œ"],\n'
            '  "info_delivery": ["ì •ë³´ ì „ë‹¬ ë°©ì‹ íŠ¹ì§• 3~6ê°œ"]\n'
            '}'
        )

    def _build_hooking_prompt() -> str:
        return (
            _persona() + '\n\n'
            '2. í›„í‚¹ í”„ë¡¬í”„íŠ¸ â€” "ì˜ìƒì— ì“°ì¸ í›„í‚¹ íŒ¨í„´ì€?"\n'
            'ëŒ€ë³¸ì˜ ì‹œì‘ë¶€(ê°€ëŠ¥í•˜ë©´ ì²« ë¬¸ì¥ ê¸°ì¤€)ì—ì„œ ì‹œì²­ìì˜ ê¶ê¸ˆì¦ì„ ìœ ë°œí•œ í•µì‹¬ì„ 1ì¤„ë¡œ "ìš”ì•½"í•˜ê³ , ì‚¬ìš©ëœ í›„í‚¹ íŒ¨í„´ì„ ë¶„ë¥˜í•´ í‘œë¡œ ì‘ì„±í•˜ì„¸ìš”.\n'
            'ì¶œë ¥ì€ ë§ˆí¬ë‹¤ìš´ í‘œ í•œ ê°œë§Œ(ì—´ ë¨¸ë¦¬ í¬í•¨), ë‹¤ë¥¸ í…ìŠ¤íŠ¸ ê¸ˆì§€.\n'
            '| ğŸ¤” í›„í‚¹ ìš”ì•½ | íŒ¨í„´(ë¶„ë¥˜) |\n| :--- | :--- |\n| (ì‹œì‘ë¶€ ìš”ì•½ 1ì¤„) | (ì˜ˆ: ì˜ë¬¸ì œì‹œ/ê³¼ì¥/ë°˜ì „/ìœ„ê¸°ì œì‹œ/ê¸ˆê¸°ë°œí™”/ê°•í•œëª…ë ¹/ëª¨ìˆœ ì œì‹œ ë“±) |'
        )

    def _build_structure_prompt() -> str:
        return (
            _persona() + '\n\n'
            '1. ê¸°ìŠ¹ì „ê²° í”„ë¡¬í”„íŠ¸ â€” "ì˜ìƒì— ë‚˜íƒ€ë‚˜ëŠ” ê¸°ìŠ¹ì „ê²° êµ¬ì¡°ëŠ”?"\n'
            'ëŒ€ë³¸ì—ì„œ ê¸°Â·ìŠ¹Â·ì „Â·ê²°ì˜ í•µì‹¬ì„ ê° 1ë¬¸ì¥ìœ¼ë¡œ "ìš”ì•½"í•´ í‘œë¡œ ì‘ì„±í•˜ì„¸ìš”(ì›ë¬¸ ë³µì‚¬ ê¸ˆì§€).\n'
            'ì¶œë ¥ì€ ë§ˆí¬ë‹¤ìš´ í‘œ í•œ ê°œë§Œ, ë‹¤ë¥¸ í…ìŠ¤íŠ¸ ê¸ˆì§€.\n'
            '| êµ¬ë¶„ | ìš”ì•½ |\n| :--- | :--- |\n| ê¸° (ìƒí™© ë„ì…) | ... |\n| ìŠ¹ (ì‚¬ê±´ ì „ê°œ) | ... |\n| ì „ (ìœ„ê¸°/ì „í™˜) | ... |\n| ê²° (ê²°ë§) | ... |'
        )

    def _parse_material_sections(text: str):
        # Prefer strict JSON parse; fallback to regex capture
        import re, json as _json
        main_idea = ''
        core_materials = []
        lang_patterns = []
        emotion_points = []
        info_delivery = []
        t = (text or '').strip()
        if not t:
            return {
                'main_idea': main_idea,
                'core_materials': core_materials,
                'lang_patterns': lang_patterns,
                'emotion_points': emotion_points,
                'info_delivery': info_delivery
            }
        # Try JSON
        try:
            payload = _json.loads(t)
            if isinstance(payload, dict):
                main_idea = str(payload.get('main_idea') or '').strip()
                core_materials = [str(x).strip() for x in (payload.get('core_materials') or []) if str(x).strip()][:12]
                lang_patterns = [str(x).strip() for x in (payload.get('lang_patterns') or []) if str(x).strip()][:12]
                emotion_points = [str(x).strip() for x in (payload.get('emotion_points') or []) if str(x).strip()][:12]
                info_delivery = [str(x).strip() for x in (payload.get('info_delivery') or []) if str(x).strip()][:12]
                return {
                    'main_idea': main_idea,
                    'core_materials': core_materials,
                    'lang_patterns': lang_patterns,
                    'emotion_points': emotion_points,
                    'info_delivery': info_delivery
                }
        except Exception:
            # try to extract JSON object inside code fences or surrounding text
            try:
                start = t.index('{')
                end = t.rindex('}') + 1
                payload = _json.loads(t[start:end])
                if isinstance(payload, dict):
                    main_idea = str(payload.get('main_idea') or '').strip()
                    core_materials = [str(x).strip() for x in (payload.get('core_materials') or []) if str(x).strip()][:12]
                    lang_patterns = [str(x).strip() for x in (payload.get('lang_patterns') or []) if str(x).strip()][:12]
                    emotion_points = [str(x).strip() for x in (payload.get('emotion_points') or []) if str(x).strip()][:12]
                    info_delivery = [str(x).strip() for x in (payload.get('info_delivery') or []) if str(x).strip()][:12]
                    return {
                        'main_idea': main_idea,
                        'core_materials': core_materials,
                        'lang_patterns': lang_patterns,
                        'emotion_points': emotion_points,
                        'info_delivery': info_delivery
                    }
            except Exception:
                pass
        # Fallback: header-based capture
        t = t.replace('\r', '')
        m = re.search(r"ë©”ì¸\s*ì•„ì´ë””ì–´\s*\(Main\s*Idea\)\s*[:ï¼š]\s*(.+)", t)
        if m:
            main_idea = m.group(1).strip()
        def capture_list_after(header_patterns, stop_patterns):
            pat = re.compile(header_patterns, re.I)
            stop = re.compile(stop_patterns, re.I) if stop_patterns else None
            lines = t.split('\n')
            capturing = False
            acc = []
            for line in lines:
                if not capturing and pat.search(line):
                    capturing = True
                    continue
                if capturing:
                    if stop and stop.search(line):
                        break
                    s = line.strip()
                    if not s:
                        continue
                    if re.match(r"^\s*(ë©”ì¸\s*ì•„ì´ë””ì–´|í•µì‹¬\s*ì†Œì¬|3-1|3-2|3-3)\b", s):
                        break
                    s = re.sub(r"^[-*â€¢Â·]\s*", '', s)
                    acc.append(s)
            return [x for x in acc if x and len(x) > 1][:12]
        core_materials = capture_list_after(r"í•µì‹¬\s*ì†Œì¬\s*\(Core\s*Materials\)\s*:?", r"^(3-1|3-2|3-3)\b")
        lang_patterns = capture_list_after(r"^(3-1\s*ë°˜ë³µë˜ëŠ”\s*ì–¸ì–´\s*íŒ¨í„´)\b|ë°˜ë³µë˜ëŠ”\s*ì–¸ì–´\s*íŒ¨í„´\s*[:ï¼š]", r"^(3-2|3-3)\b")
        emotion_points = capture_list_after(r"^(3-2\s*ê°ì •\s*ëª°ì…\s*í¬ì¸íŠ¸)\b|ê°ì •\s*ëª°ì….*[:ï¼š]", r"^(3-3)\b")
        info_delivery = capture_list_after(r"^(3-3\s*ì •ë³´\s*ì „ë‹¬\s*ë°©ì‹\s*íŠ¹ì§•)\b|ì •ë³´\s*ì „ë‹¬\s*ë°©ì‹.*[:ï¼š]", None)
        return {
            'main_idea': main_idea,
            'core_materials': core_materials,
            'lang_patterns': lang_patterns,
            'emotion_points': emotion_points,
            'info_delivery': info_delivery
        }

    def _clean_sentences_ko(text: str):
        t = (text or '')
        # remove brackets and markers
        import re
        t = re.sub(r"\[[^\]]*\]", " ", t)
        t = re.sub(r"^\s*>>.*", " ", t, flags=re.MULTILINE)
        t = re.sub(r"\b(ìŒì•…|ë°•ìˆ˜|ì›ƒìŒ|ì¹¨ë¬µ|ë°°ê²½ìŒ|ê¸°ì¹¨)\b", " ", t, flags=re.IGNORECASE)
        t = t.replace('\r', '\n')
        t = re.sub(r"\n{2,}", "\n", t)
        t = re.sub(r"[\t ]{2,}", " ", t)
        # Korean sentence ending hints
        t = re.sub(r"(ìš”|ë‹¤|ì£ |ë„¤|ìŠµë‹ˆë‹¤|ìŠµë‹ˆê¹Œ|ë„¤ìš”|êµ°ìš”)([.!?])", r"\1\2\n", t)
        # split
        parts = re.split(r"(?<=[.!?â€¦]|\n)\s+", t)
        parts = [p.strip() for p in parts if p and p.strip()]
        # merge short
        out = []
        buf = ''
        MIN = 10
        for p in parts:
            cur = (buf + ' ' + p).strip() if buf else p
            if len(cur) < MIN:
                buf = cur
                continue
            out.append(cur)
            buf = ''
        if buf:
            out.append(buf)
        # remove noise
        out = [s for s in out if len(re.sub(r"[^\w\dê°€-í£]", "", s)) >= 3]
        return out[:300]

    def _estimate_dopamine(sentence: str) -> int:
        # Richer heuristic for varied scores when LLM parsing fails
        s = (sentence or '').strip()
        s_lower = s.lower()
        score = 5
        # curiosity words
        if any(k in s_lower for k in ['ì™œ', 'ì–´ë–»ê²Œ', 'ì •ë§', 'ì¶©ê²©', 'ë°˜ì „', 'ê²½ì•…', 'ëŒ€ë°•', 'ì†Œë¦„', 'ë¹„ë°€', 'ìµœì´ˆ', 'ê¸ˆì§€', 'ê²½ê³ ']):
            score += 2
        # punctuation intensity
        excl = s.count('!')
        quest = s.count('?')
        score += min(2, excl) + min(2, quest)
        # numbers and superlatives
        if any(ch.isdigit() for ch in s):
            score += 1
        if any(k in s_lower for k in ['ê°€ì¥', 'ìµœê³ ', 'ìµœì•…', 'ì²«', 'ì™„ì „']):
            score += 1
        # length normalization
        ln = len(s)
        if ln < 20:
            score -= 1
        elif ln > 120:
            score -= 1
        return max(1, min(10, score))

    def _safe_json_arr(text: str):
        try:
            obj = json.loads(text)
            return obj if isinstance(obj, list) else []
        except Exception:
            return []

    def _build_dopamine_prompt(sentences):
        header = 'ë‹¤ìŒ "ë¬¸ì¥ ë°°ì—´"ì— ëŒ€í•´, ê° ë¬¸ì¥ë³„ë¡œ ê¶ê¸ˆì¦/ë„íŒŒë¯¼ ìœ ë°œ ì •ë„ë¥¼ 1~10 ì •ìˆ˜ë¡œ í‰ê°€í•˜ê³ , ê·¸ ì´ìœ ë¥¼ ê°„ë‹¨íˆ ì„¤ëª…í•˜ì„¸ìš”. ë°˜ë“œì‹œ JSON ë°°ì—´ë¡œë§Œ, ìš”ì†ŒëŠ” {"sentence":"ë¬¸ì¥","level":ì •ìˆ˜,"reason":"ì´ìœ "} í˜•íƒœë¡œ ì¶œë ¥í•˜ì„¸ìš”. ì—¬ëŠ” ëŒ€ê´„í˜¸ë¶€í„° ë‹«ëŠ” ëŒ€ê´„í˜¸ê¹Œì§€ ì™¸ í…ìŠ¤íŠ¸ëŠ” ì¶œë ¥í•˜ì§€ ë§ˆì„¸ìš”.'
        return header + '\n\në¬¸ì¥ ë°°ì—´:\n' + json.dumps(sentences, ensure_ascii=False)

    # --- Validators to strictly require LLM-formatted outputs ---
    def _is_md_table(text: str) -> bool:
        t = (text or '').strip()
        return '|' in t and '\n' in t and t.count('|') >= 6

    def _looks_like_structure_table(text: str) -> bool:
        t = (text or '').lower()
        return ('| ê¸°' in t) and ('| ìŠ¹' in t) and ('| ì „' in t) and ('| ê²°' in t)

    def _material_json_ok(text: str) -> bool:
        try:
            obj = json.loads(text)
            return (
                isinstance(obj, dict) and
                isinstance(obj.get('main_idea', ''), str) and
                isinstance(obj.get('core_materials', []), list) and
                isinstance(obj.get('lang_patterns', []), list) and
                isinstance(obj.get('emotion_points', []), list) and
                isinstance(obj.get('info_delivery', []), list)
            )
        except Exception:
            return False

    def _call_strict(kind: str, prompt: str, content: str, validator, tries: int = 3) -> str:
        last = ''
        for _ in range(max(1, tries)):
            last = (_call_gemini(prompt, content) or '').strip()
            if validator(last):
                break
            try:
                time.sleep(0.3)
            except Exception:
                pass
        return last

    def _call_array_only(kind: str, label: str, text: str, min_len: int = 3, max_len: int = 8) -> list:
        prompt = (
            _persona() + '\n\n'
            f'ì•„ë˜ ëŒ€ë³¸ì„ ì°¸ê³ í•´ "{label}" í•­ëª©ì„ {min_len}~{max_len}ê°œ ì¶”ì¶œí•˜ì„¸ìš”.\n'
            'ë°˜ë“œì‹œ JSON ë°°ì—´ë¡œë§Œ ì¶œë ¥í•˜ì„¸ìš”. ì˜ˆ: ["í•­ëª©1","í•­ëª©2"]\n'
            'ë¶ˆë¦¿/ì„¤ëª…/ì½”ë“œíœìŠ¤/ê¸°íƒ€ í…ìŠ¤íŠ¸ ê¸ˆì§€.'
        )
        out = []
        try:
            raw = _call_gemini(prompt, text)
            arr = json.loads(raw)
            if isinstance(arr, list):
                out = [str(x).strip() for x in arr if str(x).strip()][:max_len]
        except Exception:
            out = []
        return out

    def _analyze_video_fast(doc):  # type: ignore
        transcript = (doc or {}).get('transcript_text') or ''
        if not transcript:
            raise RuntimeError('no transcript_text in DB')
        # Trim overly long transcripts to improve latency
        max_chars = int(os.getenv('GEMINI_MAX_CHARS') or '12000')
        tshort = transcript if len(transcript) <= max_chars else transcript[:max_chars]
        # í›„í‚¹ ì…ë ¥ì€ ì‹œì‘ë¶€ ìš”ì•½ ì •í™•ë„ë¥¼ ìœ„í•´ ì²˜ìŒ 2~3ë¬¸ì¥ë§Œ ì „ë‹¬
        first_sents = _clean_sentences_ko(tshort)[:3]
        hook_input = ' '.join(first_sents)[:800]
        # Direct LLM calls without strict validation - just get the response
        results = { 'material': '', 'hooking': '', 'structure': '' }
        
        # Combine all analyses into ONE LLM call to reduce API calls
        import time
        
        # Single combined prompt for all analyses (detailed for quality)
        combined_prompt = """ì˜ìƒ ëŒ€ë³¸ì„ ì •ë°€ ë¶„ì„í•˜ì—¬ ì•„ë˜ JSON í˜•ì‹ìœ¼ë¡œ ì •í™•íˆ ì¶œë ¥í•˜ì„¸ìš”. 
ë°˜ë“œì‹œ ê¸°ìŠ¹ì „ê²° 4ê°œ íŒŒíŠ¸ë¥¼ ëª¨ë‘ í¬í•¨í•´ì•¼ í•©ë‹ˆë‹¤. JSONë§Œ ì¶œë ¥:
{
  "material": "ì˜ìƒì˜ í•µì‹¬ ì†Œì¬ì™€ ì£¼ì œë¥¼ êµ¬ì²´ì ìœ¼ë¡œ 3-5ë¬¸ì¥ìœ¼ë¡œ ìš”ì•½. ë“±ì¥ì¸ë¬¼, ìƒí™©, ì£¼ìš” ì‚¬ê±´ì„ í¬í•¨",
  "hooking": "ì²« 1-2ë¬¸ì¥ì—ì„œ ì‹œì²­ì í˜¸ê¸°ì‹¬ì„ ìœ ë°œí•˜ëŠ” êµ¬ì²´ì  ìš”ì†Œì™€ ê¸°ë²•ì„ 1ë¬¸ì¥ìœ¼ë¡œ ì„¤ëª…",
  "structure": "ê¸°: (êµ¬ì²´ì  ë„ì… ìƒí™© ì„¤ëª…), ìŠ¹: (ê°ˆë“±ì´ë‚˜ ì‚¬ê±´ì´ ì „ê°œë˜ëŠ” ë¶€ë¶„), ì „: (ë°˜ì „ì´ë‚˜ í´ë¼ì´ë§¥ìŠ¤ ë¶€ë¶„), ê²°: (í•´ê²°ì´ë‚˜ ë§ˆë¬´ë¦¬ ë¶€ë¶„)"
}
ì¤‘ìš”: structureëŠ” ë°˜ë“œì‹œ ê¸°, ìŠ¹, ì „, ê²° 4ê°œ ëª¨ë‘ ì‘ì„±í•˜ì„¸ìš”.

ëŒ€ë³¸ ë¶„ì„:"""
        
        try:
            # Single API call for all three analyses
            # Longer delay for better quality
            time.sleep(1.5)  # Increased delay for stability with lower concurrency
            combined_resp = _call_gemini(combined_prompt, tshort[:6000])  # More context for better analysis
            
            # Parse combined response
            if combined_resp:
                # Clean response to extract JSON
                resp_clean = combined_resp.strip()
                if resp_clean.startswith('```json'):
                    resp_clean = resp_clean[7:]
                if resp_clean.startswith('```'):
                    resp_clean = resp_clean[3:]
                if resp_clean.endswith('```'):
                    resp_clean = resp_clean[:-3]
                resp_clean = resp_clean.strip()
                
                try:
                    # Try to parse as JSON
                    parsed = json.loads(resp_clean)
                    results['material'] = parsed.get('material', '')[:2000] or 'ì†Œì¬ ë¶„ì„ ì‹¤íŒ¨'
                    results['hooking'] = parsed.get('hooking', '')[:1000] or 'í›„í‚¹ ë¶„ì„ ì‹¤íŒ¨'
                    # Increase structure field limit to prevent truncation
                    structure = parsed.get('structure', '')
                    if structure and all(part in structure for part in ['ê¸°:', 'ìŠ¹:', 'ì „:', 'ê²°:']):
                        results['structure'] = structure[:2000]  # Increased limit
                    else:
                        results['structure'] = structure[:2000] if structure else 'êµ¬ì¡° ë¶„ì„ ì‹¤íŒ¨'
                except Exception as e:
                    # If JSON parsing fails, try to extract manually
                    print(f"JSON parsing failed: {e}, trying manual extraction")
                    
                    # Try to extract each field manually from the response
                    if '"material"' in combined_resp and '"hooking"' in combined_resp and '"structure"' in combined_resp:
                        try:
                            # Extract material
                            mat_start = combined_resp.find('"material"') + len('"material"')
                            mat_start = combined_resp.find('"', mat_start) + 1
                            mat_end = combined_resp.find('"', mat_start)
                            while mat_end > 0 and combined_resp[mat_end-1] == '\\':
                                mat_end = combined_resp.find('"', mat_end + 1)
                            results['material'] = combined_resp[mat_start:mat_end] if mat_end > mat_start else 'ì†Œì¬ ì¶”ì¶œ ì‹¤íŒ¨'
                            
                            # Extract hooking
                            hook_start = combined_resp.find('"hooking"') + len('"hooking"')
                            hook_start = combined_resp.find('"', hook_start) + 1
                            hook_end = combined_resp.find('"', hook_start)
                            while hook_end > 0 and combined_resp[hook_end-1] == '\\':
                                hook_end = combined_resp.find('"', hook_end + 1)
                            results['hooking'] = combined_resp[hook_start:hook_end] if hook_end > hook_start else 'í›„í‚¹ ì¶”ì¶œ ì‹¤íŒ¨'
                            
                            # Extract structure
                            struct_start = combined_resp.find('"structure"') + len('"structure"')
                            struct_start = combined_resp.find('"', struct_start) + 1
                            struct_end = combined_resp.find('"', struct_start)
                            while struct_end > 0 and combined_resp[struct_end-1] == '\\':
                                struct_end = combined_resp.find('"', struct_end + 1)
                            results['structure'] = combined_resp[struct_start:struct_end] if struct_end > struct_start else 'êµ¬ì¡° ì¶”ì¶œ ì‹¤íŒ¨'
                        except:
                            # Last resort: use the full response
                            results['material'] = combined_resp[:600] if combined_resp else 'ë¶„ì„ ì‹¤íŒ¨'
                            results['hooking'] = 'í›„í‚¹ ë¶„ì„ ì‹¤íŒ¨'
                            results['structure'] = 'êµ¬ì¡° ë¶„ì„ ì‹¤íŒ¨'
                    else:
                        # Response doesn't look like JSON at all
                        results['material'] = combined_resp[:600] if combined_resp else 'ë¶„ì„ ì‹¤íŒ¨'
                        results['hooking'] = 'í›„í‚¹ ë¶„ì„ ì‹¤íŒ¨'
                        results['structure'] = 'êµ¬ì¡° ë¶„ì„ ì‹¤íŒ¨'
            else:
                results['material'] = 'ì‘ë‹µ ì—†ìŒ'
                results['hooking'] = 'ì‘ë‹µ ì—†ìŒ'
                results['structure'] = 'ì‘ë‹µ ì—†ìŒ'
                
        except Exception as e:
            print(f"Combined analysis error: {e}")
            results['material'] = f'ë¶„ì„ ì˜¤ë¥˜: {str(e)[:100]}'
            results['hooking'] = 'ë¶„ì„ ì˜¤ë¥˜'
            results['structure'] = 'ë¶„ì„ ì˜¤ë¥˜'
        # dopamine graph - simplified to reduce API calls
        sentences = _clean_sentences_ko(tshort)[:30]  # Limit to 30 sentences
        dopamine_graph = []
        # Skip LLM for dopamine to save API calls - use heuristic only
        for s in sentences:
            dopamine_graph.append({ 
                'sentence': s[:200], 
                'level': _estimate_dopamine(s), 
                'reason': 'auto' 
            })
        # parse material into sections for new detail boxes
        material_sections = _parse_material_sections(results['material'])
        
        # Always fill sections if empty - don't require strict format
        if not material_sections.get('main_idea') and results['material']:
            # Extract first meaningful line as main idea
            lines = results['material'].split('\n')
            for line in lines:
                if line.strip() and len(line.strip()) > 10:
                    material_sections['main_idea'] = line.strip()[:200]
                    break
                    
        # If still no sections, make direct calls
        if not material_sections.get('core_materials'):
            try:
                resp = _call_gemini(_persona() + '\n\ní•µì‹¬ ì†Œì¬ 3~7ê°œë¥¼ ì‰¼í‘œë¡œ êµ¬ë¶„í•´ ë‚˜ì—´í•˜ì„¸ìš”. ë‹¤ë¥¸ ì„¤ëª… ì—†ì´ ì†Œì¬ë§Œ.', tshort[:3000])
                if resp:
                    items = [x.strip() for x in resp.replace('\n', ',').split(',') if x.strip()][:7]
                    if items:
                        material_sections['core_materials'] = items
            except Exception:
                pass
                
        # Ensure all arrays have actual content
        if not material_sections.get('lang_patterns') or material_sections['lang_patterns'] == ['ë°˜ë³µ í‘œí˜„ ë¶„ì„ ì¤‘', 'íŒ¨í„´ ì¶”ì¶œ ì¤‘']:
            try:
                resp = _call_gemini("ëŒ€ë³¸ì—ì„œ ë°˜ë³µë˜ëŠ” êµ¬ì²´ì ì¸ ì–¸ì–´ íŒ¨í„´, ë§íˆ¬, í‘œí˜„ 3-5ê°œë¥¼ ì‰¼í‘œë¡œ êµ¬ë¶„í•´ ë‚˜ì—´. ì˜ˆ: '~ì–ì•„ìš”', 'ê·¸ëŸ°ë° ~', 'ì´ê²Œ ~':", tshort[:3000])
                if resp:
                    items = [x.strip() for x in resp.replace('\n', ',').split(',') if x.strip()][:5]
                    if items:
                        material_sections['lang_patterns'] = items
            except:
                material_sections['lang_patterns'] = ['íŒ¨í„´ ë¶„ì„ ì‹¤íŒ¨']
                
        if not material_sections.get('emotion_points') or material_sections['emotion_points'] == ['ê°ì • í¬ì¸íŠ¸ ë¶„ì„ ì¤‘', 'ëª°ì… ìš”ì†Œ ì¶”ì¶œ ì¤‘']:
            try:
                resp = _call_gemini("ì‹œì²­ìì˜ ê°ì •ì„ ìê·¹í•˜ëŠ” êµ¬ì²´ì  ëŒ€ì‚¬ë‚˜ ìƒí™© 3-5ê°œë¥¼ ì‰¼í‘œë¡œ êµ¬ë¶„í•´ ë‚˜ì—´:", tshort[:3000])
                if resp:
                    items = [x.strip() for x in resp.replace('\n', ',').split(',') if x.strip()][:5]
                    if items:
                        material_sections['emotion_points'] = items
            except:
                material_sections['emotion_points'] = ['ê°ì • ë¶„ì„ ì‹¤íŒ¨']
                
        if not material_sections.get('info_delivery') or material_sections['info_delivery'] == ['ì „ë‹¬ ë°©ì‹ ë¶„ì„ ì¤‘', 'êµ¬ì„± íŠ¹ì§• ì¶”ì¶œ ì¤‘']:
            try:
                resp = _call_gemini("ì˜ìƒì˜ ì •ë³´ ì „ë‹¬ ë°©ì‹ íŠ¹ì§• (ëŒ€í™”ì²´, ì„¤ëª…, í¸ì§‘ ìŠ¤íƒ€ì¼ ë“±) 3-5ê°œë¥¼ ì‰¼í‘œë¡œ êµ¬ë¶„í•´ ë‚˜ì—´:", tshort[:3000])
                if resp:
                    items = [x.strip() for x in resp.replace('\n', ',').split(',') if x.strip()][:5]
                    if items:
                        material_sections['info_delivery'] = items
            except:
                material_sections['info_delivery'] = ['ì „ë‹¬ ë°©ì‹ ë¶„ì„ ì‹¤íŒ¨']
        return {
            'material': results['material'][:2000] if results['material'] else None,
            'material_main_idea': material_sections.get('main_idea')[:1000] if material_sections.get('main_idea') else None,
            'material_core_materials': material_sections.get('core_materials') or None,
            'material_lang_patterns': material_sections.get('lang_patterns') or None,
            'material_emotion_points': material_sections.get('emotion_points') or None,
            'material_info_delivery': material_sections.get('info_delivery') or None,
            'hooking': results['hooking'][:2000] if results['hooking'] else None,
            'narrative_structure': results['structure'][:4000] if results['structure'] else None,  # Enough space for full ê¸°ìŠ¹ì „ê²°
            'dopamine_graph': dopamine_graph,
            'analysis_transcript_len': len(transcript),
            'last_modified': int(time.time()*1000)
        }

app = Flask(__name__)

@app.after_request
def add_cors_headers(resp):
    try:
        resp.headers['Access-Control-Allow-Origin'] = '*'
        resp.headers['Access-Control-Allow-Headers'] = 'Content-Type, Authorization'
        resp.headers['Access-Control-Allow-Methods'] = 'GET, POST, OPTIONS'
    except Exception:
        pass
    return resp


@app.route('/', methods=['POST', 'OPTIONS'])
@app.route('/analyze_one', methods=['POST', 'OPTIONS'])
@app.route('/api/analyze_one', methods=['POST', 'OPTIONS'])
def analyze_one():
    if request.method == 'OPTIONS':
        return ('', 204)
    # Readiness: _analyze_videoëŠ” ì‚¬ìš©í•˜ì§€ ì•Šìœ¼ë¯€ë¡œ _load_sbë§Œ í™•ì¸
    if _load_sb is None:
        return jsonify({ 'ok': False, 'error': 'server_not_ready' }), 500
    try:
        stage = 'load_sb'
        sb = _load_sb()
        body = {}
        try:
            body = request.get_json(force=True) or {}
        except Exception:
            body = {}
        vid = str(body.get('id') or '').strip()
        if not vid:
            return jsonify({ 'ok': False, 'error': 'missing id' }), 400
        stage = 'fetch_video'
        row = sb.table('videos').select('*').eq('id', vid).limit(1).execute()
        rows = getattr(row, 'data', []) or []
        if not rows:
            return jsonify({ 'ok': False, 'error': 'not_found' }), 404
        video = rows[0]
        stage = 'analyze'
        # use faster analyzer
        updated = _analyze_video_fast(video) or {}
        if updated:
            # ìŠ¤í‚¤ë§ˆì— ì—†ëŠ” ì»¬ëŸ¼ì€ ì œê±° + None ê°’ ì œì™¸
            allowed = set(video.keys())
            payload = { k: v for k, v in updated.items() if k in allowed and v is not None }
            # ë¹ˆ ë°°ì—´ë„ ì œì™¸ (DBê°€ nullì„ ê¸°ëŒ€í•˜ëŠ” ê²½ìš°)
            filtered_payload = {}
            for k, v in payload.items():
                if isinstance(v, list) and len(v) == 0:
                    continue  # skip empty arrays
                if isinstance(v, str) and v.strip() == '':
                    continue  # skip empty strings
                filtered_payload[k] = v
            if filtered_payload:
                stage = 'update'
                sb.table('videos').update(filtered_payload).eq('id', vid).execute()
            payload = filtered_payload  # use filtered for response
        wanted = list(updated.keys()) if updated else []
        saved = list(payload.keys()) if updated else []
        skipped = [k for k in wanted if k not in (saved or [])]
        # ë””ë²„ê¹…: ì‹¤ì œ ì €ì¥ëœ ê°’ ìƒ˜í”Œ í™•ì¸
        sample_fields = {}
        debug_info = {}
        if updated:
            for k in ['material', 'hooking', 'narrative_structure', 'material_core_materials', 'material_lang_patterns']:
                v = updated.get(k)
                if v is None:
                    debug_info[k] = 'None'
                elif isinstance(v, list):
                    debug_info[k] = f'list({len(v)} items)'
                    if len(v) > 0:
                        sample_fields[k] = str(v[0])[:50] if v else '[]'
                elif isinstance(v, str):
                    debug_info[k] = f'str({len(v)} chars)'
                    sample_fields[k] = v[:100] + '...' if len(v) > 100 else v
                else:
                    debug_info[k] = f'{type(v).__name__}'
        return jsonify({ 'ok': True, 'updated': bool(updated), 'saved_keys': saved, 'skipped_keys': skipped, 'sample': sample_fields, 'debug': debug_info })
    except Exception as e:
        app.logger.exception('analyze_one failed')
        return jsonify({ 'ok': False, 'error': str(e), 'stage': locals().get('stage', 'unknown'), 'trace': traceback.format_exc()[:2000] }), 500


@app.route('/health', methods=['GET'])
def health():
    return ('ok', 200)

@app.route('/debug', methods=['GET'])
@app.route('/api/analyze_one/debug', methods=['GET'])
def debug():
    try:
        # Count actual API keys
        key_count = 0
        
        # Check comma-separated keys
        multi_keys = os.getenv('GEMINI_API_KEYS')
        if multi_keys:
            key_count = len([k.strip() for k in multi_keys.split(',') if k.strip()])
        
        # Check numbered keys if no comma-separated found
        if key_count == 0:
            for i in range(1, 101):
                if os.getenv(f'GEMINI_API_KEY{i}'):
                    key_count += 1
        
        # Check single key as fallback
        if key_count == 0 and os.getenv('GEMINI_API_KEY'):
            key_count = 1
            
        info = {
            'has_SUPABASE_URL': bool(os.getenv('SUPABASE_URL')),
            'has_SUPABASE_SERVICE_ROLE_KEY': bool(os.getenv('SUPABASE_SERVICE_ROLE_KEY')),
            'has_SUPABASE_ANON_KEY': bool(os.getenv('SUPABASE_ANON_KEY')),
            'has_GEMINI_API_KEY': bool(os.getenv('GEMINI_API_KEY')),
            'gemini_key_count': key_count,
            'routes': ['/api/analyze_one', '/api/analyze_one/debug', '/api/health']
        }
        return jsonify({ 'ok': True, 'env': info })
    except Exception as e:
        return jsonify({ 'ok': False, 'error': str(e) }), 500


